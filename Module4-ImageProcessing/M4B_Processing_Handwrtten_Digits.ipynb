{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <summary></summary>\n",
    "         <div> <p></p> </div>\n",
    "         <div style=\"font-size: 20px; width: 800px;\"> \n",
    "              <h1>\n",
    "               <left>Basic Image Manipulation in Python</left>\n",
    "              </h1>\n",
    "              <p><left>============================================================================</left> </p>\n",
    "<pre>Course: BIOM 480A5, Spring 2025\n",
    "Instructor: Brian Munsky\n",
    "Authors: Will Raymond, Brian Munsky\n",
    "Contact Info: munsky@colostate.edu\n",
    "</pre>\n",
    "         </div>\n",
    "    </p>\n",
    "\n",
    "</html>\n",
    "\n",
    "<details>\n",
    "  <summary>Copyright info</summary>\n",
    "\n",
    "```\n",
    "Copyright 2024 Brian Munsky\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n",
    "\n",
    "2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "\n",
    "3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "```\n",
    "<details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This notebook provides a list of procedures to analyze images with the goal of trying to classify those images.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Upon completion of this notebook, you should be able to:\n",
    "\n",
    "1. Create a group of classified images to use as training data.\n",
    "2. Apply simple image manipulations to curate that data and make it is easier to process.\n",
    "3. Build a few different classifiers to exrtract information from the data.\n",
    "\n",
    "We are going to demonstrate these tools using hand-written data sets that we create ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Create Worksheet to collect data.**\n",
    "In this notebook, we are going to perform a supervised learning process to learn how to classify handwritten digits. But, before we can do any classification, we are going to need a bunch of training data. For this, we need to design an experiment where we know the answers.  In this case, I created a handout of boxes for you to write numbers.  Here is how I created that handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 144 random images with replacement from the set 'box0.jpg', 'box1.jpg', ..., 'box9.jpg'.\n",
    "# Then, display the images in a 12x12 grid, and save the grid as 'montage.png'.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility.\n",
    "np.random.seed(1)\n",
    "\n",
    "# Load 144 random images with replacement from the set 'box0.jpg', 'box1.jpg', ..., 'box9.jpg' in the folder\n",
    "# 'handDigits' and store them in a list.\n",
    "images = []\n",
    "labelPage = []\n",
    "for i in range(144):\n",
    "    ri = random.randint(0, 9)\n",
    "    # Append the image to the list.\n",
    "    images.append(mpimg.imread('handDigits/box' + str(ri) + '.jpg'))\n",
    "    # Append the label to the list.\n",
    "    labelPage.append(ri)\n",
    "\n",
    "# Create a 12x12 grid of subplots.\n",
    "fig, axs = plt.subplots(12, 12, figsize=(12, 12))\n",
    "\n",
    "# Display the images in the grid.\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        axs[i, j].imshow(images[i * 12 + j])\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "# Save the grid\n",
    "plt.savefig('handDigits/handDigitSheet.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Collect and Process the Collected Data.**\n",
    "\n",
    "## **Loading the data into python.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image 'handDigits/scannedSheet.pdf,' with a single page,\n",
    "# then convert it to a 2D NumPy array with high resolution\n",
    "# and then display the image.\n",
    "# !pip install PyMuPDF\n",
    "import fitz\n",
    "doc = fitz.open('handDigits/scannedSheetMultiPagePortrait.pdf')\n",
    "nPages = doc.page_count\n",
    "imgSet = []\n",
    "for iPage in range(nPages):\n",
    "    print(f'Opening page {iPage}')\n",
    "    page = doc.load_page(iPage)\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(3, 3))\n",
    "    img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)\n",
    "    # rotate the image 90 degrees to the left\n",
    "    # img = np.rot90(img,3)\n",
    "    imgSet.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one of the images.\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(imgSet[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning labels to the known data.\n",
    "\n",
    "In this example, I know that the first several pages all have the numbers in the same order.  So, I am going to use that order to assign labels to the collected images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, when I created the original sheet I did not set the RNG seed,\n",
    "# so the labels are not reproducible.  Instead, I am going to have to write them out by hand :(.\n",
    "labelPage = [6, 6, 0, 4, 8, 7, 6, 4, 7, 5, 9, 3,\n",
    "             8, 2, 4, 2, 1, 9, 4, 8, 9, 2, 4, 1,\n",
    "             1, 5, 7, 8, 1, 5, 6, 5, 9, 3, 8, 7,\n",
    "             7, 8, 4, 0, 8, 0, 1, 6, 0, 9, 7, 5,\n",
    "             3, 5, 1, 3, 9, 3, 3, 2, 8, 7, 1, 1,\n",
    "             5, 8, 7, 1, 4, 8, 4, 1, 8, 5, 8, 3,\n",
    "             9, 8, 9, 4, 7, 1, 9, 6, 5, 9, 3, 4,\n",
    "             2, 3, 2, 0, 9, 4, 7, 1, 1, 2, 2, 0,\n",
    "             1, 8, 6, 8, 4, 8, 3, 3, 9, 6, 9, 4,\n",
    "             7, 7, 5, 1, 5, 9, 1, 7, 9, 5, 3, 3,\n",
    "             0, 4, 1, 3, 5, 2, 5, 6, 0, 1, 2, 3,\n",
    "             0, 9, 8, 9, 1, 0, 1, 3, 9, 9, 1, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting images into individual training data points.\n",
    "\n",
    "One of the most difficult steps in working with real images, is that there can be many interesting features on a single image, and we want to separate these out.  We will learn more about segmentation in the next lesson, but for now we just want to separate out the boxes with the different numbers so we can later build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a grayscale image and display it.\n",
    "gray_img = np.mean(imgSet[0], axis=2)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the grayscale image over the rows and display the resulting 1D NumPy array.\n",
    "gray_img = np.mean(imgSet[0], axis=2)\n",
    "average_Row = np.mean(gray_img, axis=0)\n",
    "average_Column = np.mean(gray_img, axis=1)\n",
    "\n",
    "# Create two subplots, one for the average over the rows and one for the average over the columns.\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,3))\n",
    "axs[0].plot(average_Row)\n",
    "axs[0].set_title('Average over the rows')\n",
    "axs[0].set_xlabel('Column index')\n",
    "axs[0].set_ylabel('Average intensity')\n",
    "axs[1].plot(average_Column)\n",
    "axs[1].set_title('Average over the columns')\n",
    "axs[1].set_xlabel('Row index')\n",
    "axs[1].set_ylabel('Average intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colIDs = np.zeros_like(average_Row)\n",
    "rowNumber = 0\n",
    "for i in range(1, len(average_Row)-1):\n",
    "    if average_Row[i] > 250:\n",
    "        colIDs[i] = 0\n",
    "    elif average_Row[i-1] > 250:\n",
    "        rowNumber += 1\n",
    "        colIDs[i] = 0\n",
    "    elif average_Row[i+1] > 250:\n",
    "        colIDs[i] = 0\n",
    "    else:\n",
    "        colIDs[i] = rowNumber\n",
    "\n",
    "rowIDs = np.zeros_like(average_Column)\n",
    "colNumber = 0\n",
    "for i in range(1, len(average_Column)-1):\n",
    "    if average_Column[i] > 250:\n",
    "        rowIDs[i] = 0\n",
    "    elif average_Column[i-1] > 250:\n",
    "        colNumber += 1\n",
    "        rowIDs[i] = 0\n",
    "    elif average_Column[i+1] > 250:\n",
    "        rowIDs[i] = 0    \n",
    "    else:\n",
    "        rowIDs[i] = colNumber\n",
    "\n",
    "# Create two subplots, one for the RowIDs and one for the ColIDs.\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,3))\n",
    "axs[0].plot(rowIDs)\n",
    "axs[0].set_title('RowIDs')\n",
    "axs[0].set_xlabel('Row index')\n",
    "axs[0].set_ylabel('Row Number')\n",
    "axs[1].plot(colIDs)\n",
    "axs[1].set_title('ColIDs')\n",
    "axs[1].set_xlabel('Column index')\n",
    "axs[1].set_ylabel('Column Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array of the same size as the grayscale image, but where the value of each entry is \n",
    "# 12*rowID + colID, where rowID and colID are the row and column IDs of the corresponding entry in the\n",
    "# grayscale image.\n",
    "mask = np.zeros_like(gray_img).astype(int)\n",
    "for i in range(1, len(average_Column)):\n",
    "    for j in range(1, len(average_Row)):\n",
    "        if rowIDs[i]>0 and colIDs[j]>0:\n",
    "            mask[i][j] = 12*(rowIDs[i]-1) + colIDs[j] \n",
    "\n",
    "# Display the mask.\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_img*((mask==37)+(mask==64)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the mask and create a subimage from the grayscale image for each unique value in the mask.\n",
    "# Then, display the subimages in a 12x12 grid.\n",
    "subImagesTrain = []\n",
    "row = []\n",
    "col = []\n",
    "\n",
    "for i in range(1,np.max(mask)+1):\n",
    "    row.append(np.any(mask==i, axis=1))\n",
    "    col.append(np.any(mask==i, axis=0))\n",
    "\n",
    "for i in range(1,np.max(mask)+1):\n",
    "    if np.sum(mask==i)>6000:\n",
    "        rmin, rmax = np.where(row[i-1])[0][[0, -1]]\n",
    "        cmin, cmax = np.where(col[i-1])[0][[0, -1]]\n",
    "        subImagesTrain.append(gray_img[rmin:rmax, cmin:cmax])\n",
    "\n",
    "# Find the average size of the subimages\n",
    "avgSize = np.mean([[img.shape[0], img.shape[1]] for img in subImagesTrain], axis=0).astype(int)\n",
    "print(f'Average size of subImagesTrain: {avgSize}')\n",
    "\n",
    "fig, axs = plt.subplots(12, 12, figsize=(12, 12))\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        axs[i, j].imshow(subImagesTrain[i * 12 + j])\n",
    "        axs[i, j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to redo the above steps for a given page of the PDF.\n",
    "def process_page(img, expectedImagesPerPage=144):\n",
    "    # Convert the image to a grayscale image and display it.\n",
    "    gray_img = np.mean(img, axis=2)\n",
    "\n",
    "    # Crop off the margins of the image (to get rid of text where people wrote their names)\n",
    "    gray_img = gray_img[50:gray_img.shape[0]-50, 300:gray_img.shape[1]-275]\n",
    "\n",
    "    # Average the grayscale image over the rows and display the resulting 1D NumPy array.\n",
    "    average_Row = np.mean(gray_img, axis=0)\n",
    "    average_Column = np.mean(gray_img, axis=1)\n",
    "\n",
    "    colIDs = np.zeros_like(average_Row)\n",
    "    rowNumber = 0\n",
    "    for i in range(1, len(average_Row)-1):\n",
    "        if average_Row[i] > 250:  # If in a white area\n",
    "            colIDs[i] = 0\n",
    "        elif average_Row[i-1] > 250: # If in a black area to the right to a white area\n",
    "            rowNumber += 1\n",
    "            colIDs[i] = 0\n",
    "        elif average_Row[i+1] > 250: # If in a black area to the left to a white area\n",
    "            colIDs[i] = 0\n",
    "        else:\n",
    "            colIDs[i] = rowNumber\n",
    "\n",
    "    rowIDs = np.zeros_like(average_Column)\n",
    "    colNumber = 0\n",
    "    for i in range(1, len(average_Column)-1):\n",
    "        if average_Column[i] > 250:\n",
    "            rowIDs[i] = 0\n",
    "        elif average_Column[i-1] > 250:\n",
    "            colNumber += 1\n",
    "            rowIDs[i] = 0\n",
    "        elif average_Column[i+1] > 250:\n",
    "            rowIDs[i] = 0    \n",
    "        else:\n",
    "            rowIDs[i] = colNumber\n",
    "\n",
    "    mask = np.zeros_like(gray_img).astype(int)\n",
    "    for i in range(1, len(average_Column)):\n",
    "        for j in range(1, len(average_Row)):\n",
    "            if rowIDs[i]>0 and colIDs[j]>0:\n",
    "                mask[i][j] = 12*(rowIDs[i]-1) + colIDs[j]   \n",
    "\n",
    "    # Display the mask.\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(mask)\n",
    "    plt.axis('off')\n",
    "    plt.show() \n",
    "\n",
    "    subIms = []\n",
    "    for i in range(1,np.max(mask)+1):\n",
    "        # Apply threshold on image size to remove stubs.\n",
    "        if np.sum(mask==i)>6000:\n",
    "            row = np.any(mask==i, axis=1)\n",
    "            col = np.any(mask==i, axis=0)\n",
    "\n",
    "            rmin, rmax = np.where(row)[0][[0, -1]]\n",
    "            cmin, cmax = np.where(col)[0][[0, -1]]\n",
    "\n",
    "            pad = 4\n",
    "            subImage = gray_img[rmin-pad:rmax+pad, cmin-pad:cmax+pad]\n",
    "\n",
    "            # Resize the image to match the average size from above. This might require interpolation.\n",
    "            subImage = skimage.transform.resize(subImage, (avgSize[0], avgSize[1]), anti_aliasing=True)\n",
    "            \n",
    "            subIms.append(subImage)\n",
    "\n",
    "    # Check if the number of subimages is less or more than expected.\n",
    "    if len(subIms) != expectedImagesPerPage:\n",
    "        print(f'Warning: Expected {expectedImagesPerPage} images, but found {len(subIms)} images.')\n",
    "        print('skipping page')\n",
    "        return []\n",
    "    else:\n",
    "        return subIms     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process first 8 pages of the PDF for training and validation data.\n",
    "subImagesTrain = []\n",
    "i =0\n",
    "labels = []\n",
    "for page in imgSet[:8]:\n",
    "    try:\n",
    "        subImagesTrain.extend(process_page(page))\n",
    "        print(f'Processed page {i}')\n",
    "        labels = labels + labelPage\n",
    "    except:\n",
    "        print(f'Error processing image {i}')\n",
    "    i+=1 \n",
    "\n",
    "print(f'total number of subimages for training and validation: {len(subImagesTrain)}')\n",
    "\n",
    "# Process the remaining pages as testing data.\n",
    "subImagesTest = []\n",
    "for page in imgSet[8:]:\n",
    "    try:\n",
    "        subImagesTest.extend(process_page(page))\n",
    "        print(f'Processed page {i}')\n",
    "        labels = labels + labelPage\n",
    "    except:\n",
    "        print(f'Error processing image {i}')\n",
    "    i+=1 \n",
    "\n",
    "print(f'total number of subimages for testing: {len(subImagesTest)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a random 12x12 sample of the training subimages.\n",
    "randIndices = random.sample(range(len(subImagesTrain)), 144)\n",
    "fig, axs = plt.subplots(12, 12, figsize=(12, 12))\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        axs[i, j].imshow(subImagesTrain[randIndices[i * 12 + j]])\n",
    "        axs[i, j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curating Data to Remove Artificial Cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, many of the images are a bit off center, so we need to crop and pad them to make them all the same size.\n",
    "\n",
    "# Create a function that loops over all iamges and crops to remove white space at the top.\n",
    "# it then pads the bottom of the image to make it the same size as the original image.\n",
    "def crop_pad(imgs):\n",
    "\n",
    "    imgsOut = []\n",
    "    # Crop the top of each image until the average intensity of the first line is less than firstLineMean.\n",
    "    for i, img in enumerate(imgs):\n",
    "        # Find average intensity along rows and columns\n",
    "        intensityRow = np.mean(img, axis=0)\n",
    "        intensityCol = np.mean(img, axis=1)\n",
    "        # Find first row that is not white\n",
    "        cmin = np.where(intensityRow < 200)[0][0]\n",
    "        # Find last row that is not white\n",
    "        cmax = np.where(intensityRow < 200)[0][-1]\n",
    "        # Find first column that is not white\n",
    "        rmin = np.where(intensityCol < 200)[0][0]\n",
    "        # Find last column that is not white\n",
    "        rmax = np.where(intensityCol < 200)[0][-1]\n",
    "\n",
    "        imgCopy = img.copy()\n",
    "        \n",
    "        # Crop the image\n",
    "        imgCopy = imgCopy[rmin:rmax, cmin:cmax]\n",
    "        # Resize the image to the average size\n",
    "        imgCopy = skimage.transform.resize(imgCopy, (avgSize[0], avgSize[1]), anti_aliasing=True)\n",
    "        \n",
    "        imgsOut.append(imgCopy)\n",
    "\n",
    "    return imgsOut\n",
    "\n",
    "# Crop and pad the training and validation subimages.\n",
    "subImagesAdjust = crop_pad(subImagesTrain)\n",
    "subImagesTestAdjust = crop_pad(subImagesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a random 12x12 sample of the training subimages.\n",
    "randIndices = random.sample(range(len(subImagesTrain)), 144)\n",
    "\n",
    "fig, axs = plt.subplots(12, 12, figsize=(12, 12))\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        axs[i, j].imshow(subImagesAdjust[randIndices[i * 12 + j]])\n",
    "        axs[i, j].axis('off')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the subimages and find the minimum width and height of the subimages.\n",
    "minWidth = subImagesAdjust[0].shape[1]\n",
    "minHeight = subImagesAdjust[0].shape[0]\n",
    "for i in range(len(subImagesAdjust)):\n",
    "    if subImagesAdjust[i].shape[1] < minWidth:\n",
    "        minWidth = subImagesAdjust[i].shape[1]\n",
    "    if subImagesAdjust[i].shape[0] < minHeight:\n",
    "        minHeight = subImagesAdjust[i].shape[0]\n",
    "        \n",
    "# Create an average image by averaging the subimages. Truncate each subimage to the minimum width and height\n",
    "# before averaging.\n",
    "averageImage = np.zeros((minHeight, minWidth))\n",
    "for i in range(len(subImagesAdjust)):\n",
    "    averageImage += subImagesAdjust[i][:minHeight, :minWidth]\n",
    "averageImage /= len(subImagesAdjust)\n",
    "\n",
    "# Display the average image.\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(averageImage, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Compute the row and column averages of the average image and display the resulting 1D NumPy arrays.\n",
    "average_Row = np.mean(averageImage, axis=0)\n",
    "average_Column = np.mean(averageImage, axis=1)\n",
    "\n",
    "# Create two subplots, one for the average over the rows and one for the average over the columns.\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,3))\n",
    "axs[0].plot(average_Row)\n",
    "axs[0].set_title('Average over the rows')\n",
    "axs[0].set_xlabel('Column index')\n",
    "axs[0].set_ylabel('Average intensity')\n",
    "axs[1].plot(average_Column)\n",
    "axs[1].set_title('Average over the columns')\n",
    "axs[1].set_xlabel('Row index')\n",
    "axs[1].set_ylabel('Average intensity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Data and Assigning Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each subimage in the typeLabeled data, split into two new images.  \n",
    "# The first will be the top left box, and the second will be the original image with the top left box removed.\n",
    "def split_images(subImages):\n",
    "    labelList = []\n",
    "    typedList = []\n",
    "    drawingList = []\n",
    "\n",
    "    for i in range(len(subImages)):\n",
    "        for j in range(0, 1):\n",
    "            for k in range(0, 1):       \n",
    "                labImage = subImages[i][9+j:32+j, 11+k:28+k]\n",
    "                typedList.append(labImage)\n",
    "        \n",
    "                img = subImages[i].copy()\n",
    "                img[0:45, 0:45] = 255\n",
    "                # crop the image to remove the first two rows and columns\n",
    "                img = img[5+j:100+j, 6+k:86+k]\n",
    "                drawingList.append(img)\n",
    "\n",
    "                labelList.append(labels[i])\n",
    "    return typedList, drawingList, labelList\n",
    "\n",
    "typedListTrain, drawingListTrain, labelListTrain = split_images(subImagesAdjust)\n",
    "typedListTest, drawingListTest, labelListTest = split_images(subImagesTestAdjust)\n",
    "\n",
    "# Display random images in the label list in a grid.\n",
    "m=3\n",
    "n=12\n",
    "fig, axs = plt.subplots(m*2, n, figsize=(20, 8))\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        ri = random.randint(0, len(drawingListTrain)-1)\n",
    "        axs[i, j].imshow(typedListTrain[ri], cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "        axs[i+m, j].imshow(drawingListTrain[ri], cmap='gray')\n",
    "        axs[i+m, j].axis('on')\n",
    "plt.show()\n",
    "\n",
    "# Display shape of data\n",
    "print(f'Subimage: {len(subImages)}')\n",
    "print(f'Label List: {len(labelListTrain)}')\n",
    "print(f'Typed List: {len(typedListTrain)}')\n",
    "print(f'Drawing List: {len(drawingListTrain)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save all of the previous images to a folder. We don't need them\n",
    "# for this notebook, but we will reuse them later.\n",
    "!mkdir -p handDigits/images\n",
    "i = 0\n",
    "for image in drawingListTrain:\n",
    "    plt.imsave(f'handDigits/images/im_{i}.png', image, cmap='gray')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Data Size for Faster Processing and to Reduce Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The drawings are pretty big.  Let's crop away the white space and then resize them to 12x12 pixels.\n",
    "from skimage.transform import resize\n",
    "\n",
    "def findGroup(vec):\n",
    "    # find the sub-vector that contains the largest number of sequential non-zero elements\n",
    "    min = 0\n",
    "    max = 0\n",
    "    count = 1\n",
    "    maxCount = 1\n",
    "    for i in range(1,len(vec)):\n",
    "        if vec[i] > 0 or vec[i-1] > 0:\n",
    "            count += 1\n",
    "            if count > maxCount:\n",
    "                max = i\n",
    "                min = i - count + 1\n",
    "                maxCount = count\n",
    "        else:\n",
    "            count = 0\n",
    "    return min, max\n",
    "\n",
    "def cropAndResize(imgs, size=(12, 12)):\n",
    "    imgsOut = []\n",
    "    for i in range(len(imgs)):\n",
    "        # Find the average of the first lines of all images.\n",
    "        imgCopy = imgs[i].copy()\n",
    "        # try:\n",
    "        # find which rows and columns are not white\n",
    "        rows = np.min(imgCopy,axis=1) < 200\n",
    "        min0, max0 = findGroup(rows)\n",
    "\n",
    "        cols = np.min(imgCopy, axis=0) < 200\n",
    "        min1, max1 = findGroup(cols)\n",
    "        imgCopy = imgCopy[min0:max0, min1:max1]\n",
    "\n",
    "        # pad image on left and right to make square\n",
    "        pad = (imgCopy.shape[0] - imgCopy.shape[1]) // 3\n",
    "        if pad > 0:\n",
    "            imgCopy = np.pad(imgCopy, ((0, 0), (pad, pad)), mode='constant', constant_values=255)\n",
    "\n",
    "        imgsOut.append(resize(imgCopy, size, anti_aliasing=True))\n",
    "        # except:\n",
    "        #     imgsOut.append(np.zeros(size))\n",
    "        #     print(f'Error resizing image {i} - set to zero')\n",
    "    return imgsOut\n",
    "\n",
    "typedListResizedTrain = cropAndResize(typedListTrain)\n",
    "typedListResizedTest = cropAndResize(typedListTest)\n",
    "drawingListResizedTrain = cropAndResize(drawingListTrain)\n",
    "drawingListResizedTest = cropAndResize(drawingListTest)\n",
    "\n",
    "# Display the last 12 images in the drawing list in a 3x4 grid.\n",
    "fig, axs = plt.subplots(3, 4, figsize=(6, 4))\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(drawingListResizedTrain[-(i * 4 + j)], cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the classification on either the typed or the handwritten images.\n",
    "digitListTrain = drawingListResizedTrain\n",
    "digitListTest = drawingListResizedTest\n",
    "\n",
    "# Loop through the label list and create a matrix where each row is the flattened version of the corresponding image in the label list.\n",
    "dataMatrixTrain = np.zeros((len(digitListTrain),len(digitListTrain[0].flatten())))\n",
    "for i in range(len(digitListTrain)):\n",
    "    dataMatrixTrain[i] = digitListTrain[i].flatten()\n",
    "\n",
    "dataMatrixTest = np.zeros((len(digitListTest),len(digitListTest[0].flatten())))\n",
    "for i in range(len(digitListTest)):\n",
    "    dataMatrixTest[i] = digitListTest[i].flatten()\n",
    "\n",
    "# Display the first 36 images in the label list in a 3x12 grid, with the corresponding label as the title.\n",
    "fig, axs = plt.subplots(5, 20, figsize=(20, 8))\n",
    "for i in range(5):\n",
    "    for j in range(20):\n",
    "        ri = random.randint(0, len(digitListTrain)-1)\n",
    "        axs[i, j].imshow(digitListTrain[ri], cmap='gray')\n",
    "        axs[i, j].set_title(labelListTrain[ri])\n",
    "        axs[i, j].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Running Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate the labelMatrix with the labels list, and build a classifier using the first 200 images in the label list.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "nTrain = dataMatrixTrain.shape[0]\n",
    "nTest = dataMatrixTest.shape[0]\n",
    "classifier.fit(dataMatrixTrain[:nTrain], labelListTrain[:nTrain])\n",
    "\n",
    "# Use the classifier to predict the labels of the training and test data.\n",
    "predictedLabelsTrain = classifier.predict(dataMatrixTrain)\n",
    "predictedLabelsTest = classifier.predict(dataMatrixTest)\n",
    "\n",
    "# Display the last 24 images in the drawing testing list in a 4x12 grid, with the predicted labels as titles.\n",
    "fig, axs = plt.subplots(4, 18, figsize=(18, 6))\n",
    "for i in range(4):\n",
    "    for j in range(18):\n",
    "        r1 = random.randint(0, nTest-1)\n",
    "        axs[i, j].imshow(digitListTest[r1], cmap='gray')\n",
    "        axs[i, j].set_title(f'{predictedLabelsTest[r1]} {labelListTest[r1]}')\n",
    "        axs[i, j].axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('Training Accuracy:', np.mean(predictedLabelsTrain[:nTrain] == labelListTrain[:nTrain]))\n",
    "print('Testing Accuracy:', np.mean(predictedLabelsTest == labelListTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix for the classifier on the predicted labels.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusionMatrix = confusion_matrix(labelListTest, predictedLabelsTest)\n",
    "\n",
    "# Display the confusion matrix as a heatmap.\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(confusionMatrix, annot=True, cmap='YlGnBu', fmt='g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to improve the accuracy by using a different classifier.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "classifier.fit(dataMatrixTrain, labelListTrain)\n",
    "predictedLabelsTest = classifier.predict(dataMatrixTest)\n",
    "confusionMatrix = confusion_matrix(labelListTest, predictedLabelsTest)\n",
    "print('Testing Accuracy:', np.mean(predictedLabelsTest == labelListTest))\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(confusionMatrix, annot=True, cmap='YlGnBu', fmt='g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try with a support vector machine.\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC()\n",
    "classifier.fit(dataMatrixTrain, labelListTrain)\n",
    "predictedLabelsTrain = classifier.predict(dataMatrixTrain)\n",
    "predictedLabelsTest = classifier.predict(dataMatrixTest)\n",
    "\n",
    "confusionMatrix = confusion_matrix(labelListTest, predictedLabelsTest)\n",
    "print('Testing Accuracy:', np.mean(predictedLabelsTest == labelListTest))\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(confusionMatrix, annot=True, cmap='YlGnBu', fmt='g')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training images that were misclassified.\n",
    "indicesWrong = np.where(predictedLabelsTrain != labelListTrain)[0]\n",
    "fig, axs = plt.subplots(4, 12, figsize=(12, 4))\n",
    "for i in range(4):\n",
    "    for j in range(12):\n",
    "        if i * 12 + j >= len(indicesWrong):\n",
    "            continue\n",
    "        r1 = indicesWrong[i * 12 + j]\n",
    "        \n",
    "        axs[i, j].imshow(digitListTrain[r1], cmap='gray')\n",
    "        axs[i, j].set_title(f'{predictedLabelsTrain[r1]} {labelListTrain[r1]}')\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "# Show test images that were misclassified.\n",
    "indicesWrong = np.where(predictedLabelsTest != labelListTest)[0]\n",
    "fig, axs = plt.subplots(4, 12, figsize=(12, 4))\n",
    "for i in range(4):\n",
    "    for j in range(12):\n",
    "        if i * 12 + j >= len(indicesWrong):\n",
    "            continue\n",
    "        r1 = indicesWrong[i * 12 + j]\n",
    "        \n",
    "        axs[i, j].imshow(digitListTest[r1], cmap='gray')\n",
    "        axs[i, j].set_title(f'{predictedLabelsTest[r1]} {labelListTest[r1]}')\n",
    "        axs[i, j].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
